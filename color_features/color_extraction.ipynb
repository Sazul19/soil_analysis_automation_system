{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python numpy matplotlib scikit-image tensorflow fiftyone kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_color_efficientnet(image_path, k=3):\n",
    "    \"\"\"\n",
    "    Identify the dominant color in an image using EfficientNet for feature extraction and k-means clustering.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        k (int): Number of clusters for k-means. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        dominant_color_rgb (tuple): Dominant color in RGB format.\n",
    "        cluster_labels (numpy.ndarray): Cluster labels for each pixel.\n",
    "        features_flat (numpy.ndarray): Feature vectors for clustering.\n",
    "        processing_time (float): Time taken to process the image.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at path {image_path} could not be loaded.\")\n",
    "\n",
    "    # Resize the image to the input size required by EfficientNet (224x224)\n",
    "    image_resized = cv2.resize(image, (224, 224))\n",
    "\n",
    "    # Preprocess the image for EfficientNet\n",
    "    image_preprocessed = preprocess_input(image_resized)\n",
    "\n",
    "    # Load the pre-trained EfficientNetB0 model (without the top classification layer)\n",
    "    model = EfficientNetB0(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "    # Extract features for each pixel (use the last convolutional layer)\n",
    "    features = model.predict(np.expand_dims(image_preprocessed, axis=0))\n",
    "\n",
    "    # Reshape the features to (height * width, num_features)\n",
    "    height, width, num_features = features.shape[1], features.shape[2], features.shape[3]\n",
    "    features_flat = features.reshape((-1, num_features))\n",
    "\n",
    "    # Apply k-means clustering to find dominant colors\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(features_flat)\n",
    "\n",
    "    # Get the cluster centroids (feature vectors of dominant colors)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Map the clusters back to the original image pixels\n",
    "    dominant_cluster = np.argmax(np.bincount(cluster_labels))  # Find the cluster with the most pixels\n",
    "\n",
    "    # Extract the dominant color from the original image\n",
    "    dominant_color_bgr = image_resized[cluster_labels == dominant_cluster].mean(axis=0).astype(int)\n",
    "    dominant_color_rgb = tuple(reversed(dominant_color_bgr))  # Convert BGR to RGB\n",
    "\n",
    "    processing_time = time.time() - start_time\n",
    "\n",
    "    return dominant_color_rgb, cluster_labels, features_flat, processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_results(image_path, dominant_color_rgb, cluster_labels):\n",
    "    \"\"\"\n",
    "    Visualize the original image, dominant color, and color distribution.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        dominant_color_rgb (tuple): Dominant color in RGB format.\n",
    "        cluster_labels (numpy.ndarray): Cluster labels for each pixel.\n",
    "    \"\"\"\n",
    "    # Load the original image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "\n",
    "    # Create a figure for visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot the original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Plot the dominant color\n",
    "    plt.subplot(1, 3, 2)\n",
    "    dominant_color_block = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "    dominant_color_block[:, :] = dominant_color_rgb\n",
    "    plt.imshow(dominant_color_block)\n",
    "    plt.title(f\"Dominant Color (RGB: {dominant_color_rgb})\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Plot the color distribution (cluster labels)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(cluster_labels, bins=range(len(np.unique(cluster_labels)) + 1), edgecolor=\"black\")\n",
    "    plt.title(\"Color Distribution (Clusters)\")\n",
    "    plt.xlabel(\"Cluster\")\n",
    "    plt.ylabel(\"Number of Pixels\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(features_flat, cluster_labels, processing_time):\n",
    "    \"\"\"\n",
    "    Analyze the performance of the clustering process.\n",
    "\n",
    "    Args:\n",
    "        features_flat (numpy.ndarray): Feature vectors for clustering.\n",
    "        cluster_labels (numpy.ndarray): Cluster labels for each pixel.\n",
    "        processing_time (float): Time taken to process the image.\n",
    "    \"\"\"\n",
    "    # Calculate silhouette score (clustering quality)\n",
    "    silhouette_avg = silhouette_score(features_flat, cluster_labels)\n",
    "    print(f\"Silhouette Score: {silhouette_avg:.2f}\")\n",
    "\n",
    "    # Print processing time\n",
    "    print(f\"Processing Time: {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(input_folder, k=3):\n",
    "    \"\"\"\n",
    "    Process all images in the input folder to identify dominant colors and analyze performance.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing input images.\n",
    "        k (int): Number of clusters for k-means. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        results (list): A list of dictionaries containing results for each image.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Loop through all images in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):  # Check for image files\n",
    "            # Construct the full path to the image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Get the dominant color and other details\n",
    "\n",
    "            dominant_rgb, cluster_labels, features_flat, processing_time = get_dominant_color_efficientnet(image_path, k=3)\n",
    "\n",
    "            # Visualize the results\n",
    "            visualize_results(image_path, dominant_rgb, cluster_labels)\n",
    "\n",
    "            # Analyze performance\n",
    "            analyze_performance(features_flat, cluster_labels, processing_time)\n",
    "\n",
    "            # Save the results for this image\n",
    "            results.append({\n",
    "                \"filename\": filename,\n",
    "                \"dominant_color_rgb\": dominant_rgb,\n",
    "                \"processing_time\": processing_time,\n",
    "                \"silhouette_score\": silhouette_score(features_flat, cluster_labels)\n",
    "            })\n",
    "\n",
    "            return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 224 but size of corresponding boolean axis is 49",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/sala/iit/dsgp/preprocessed_data/general_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(input_folder, k)\u001b[0m\n\u001b[1;32m     18\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, filename)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Get the dominant color and other details\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m dominant_rgb, cluster_labels, features_flat, processing_time \u001b[38;5;241m=\u001b[39m \u001b[43mget_dominant_color_efficientnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Visualize the results\u001b[39;00m\n\u001b[1;32m     25\u001b[0m visualize_results(image_path, dominant_rgb, cluster_labels)\n",
      "Cell \u001b[0;32mIn[12], line 49\u001b[0m, in \u001b[0;36mget_dominant_color_efficientnet\u001b[0;34m(image_path, k)\u001b[0m\n\u001b[1;32m     46\u001b[0m dominant_cluster \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39mbincount(cluster_labels))  \u001b[38;5;66;03m# Find the cluster with the most pixels\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Extract the dominant color from the original image\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m dominant_color_bgr \u001b[38;5;241m=\u001b[39m \u001b[43mimage_resized\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdominant_cluster\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     50\u001b[0m dominant_color_rgb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(dominant_color_bgr))  \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n\u001b[1;32m     52\u001b[0m processing_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along axis 0; size of axis is 224 but size of corresponding boolean axis is 49"
     ]
    }
   ],
   "source": [
    "input_folder = \"/home/sala/iit/dsgp/preprocessed_data/general_data/\" \n",
    "results = train_model(input_folder, k=3)\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(f\"Image: {result['filename']}\")\n",
    "    print(f\"Dominant Color (RGB): {result['dominant_color_rgb']}\")\n",
    "    print(f\"Processing Time: {result['processing_time']:.2f} seconds\")\n",
    "    print(f\"Silhouette Score: {result['silhouette_score']:.2f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
