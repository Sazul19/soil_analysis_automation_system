{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tqdm.notebook import tqdm  # Progress bar for notebooks\n",
    "\n",
    "# Configuration\n",
    "TARGET_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16  # Reduced batch size for memory safety\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Custom preprocessing function\n",
    "def preprocess_image(image_path):\n",
    "    # Load image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "    image = tf.image.resize(image, TARGET_SIZE)\n",
    "    \n",
    "    # Convert to LAB\n",
    "    lab_image = tf.numpy_function(\n",
    "        lambda rgb: cv2.cvtColor(rgb.numpy(), cv2.COLOR_RGB2LAB),\n",
    "        [image],\n",
    "        tf.uint8\n",
    "    )\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    l_channel = tf.cast(lab_image[..., 0], tf.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_channel_clahe = tf.numpy_function(\n",
    "        lambda l: clahe.apply(l.numpy()),\n",
    "        [l_channel],\n",
    "        tf.uint8\n",
    "    )\n",
    "    \n",
    "    # Merge channels back\n",
    "    lab_image_clahe = tf.stack([\n",
    "        l_channel_clahe,\n",
    "        lab_image[..., 1],\n",
    "        lab_image[..., 2]\n",
    "    ], axis=-1)\n",
    "    \n",
    "    # Normalize\n",
    "    lab_image_clahe = tf.cast(lab_image_clahe, tf.float32)\n",
    "    lab_image_clahe = tf.stack([\n",
    "        lab_image_clahe[..., 0] / 100.0,\n",
    "        (lab_image_clahe[..., 1] + 128) / 255.0,\n",
    "        (lab_image_clahe[..., 2] + 128) / 255.0\n",
    "    ], axis=-1)\n",
    "    \n",
    "    return lab_image_clahe\n",
    "\n",
    "def build_dataset(image_dir, batch_size=BATCH_SIZE):\n",
    "    # Efficiently list image files without storing all paths in memory\n",
    "    image_files = tf.data.Dataset.list_files(os.path.join(image_dir, \"*.jpg\"), shuffle=True)\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    dataset = image_files.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Batch, shuffle, and prefetch for performance\n",
    "    dataset = dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobile_model(input_shape=(224, 224, 3), num_classes=5):\n",
    "    # Use MobileNetV3Small with minimal memory footprint\n",
    "    base_model = tf.keras.applications.MobileNetV3Small(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    )\n",
    "    \n",
    "    # Freeze base model to reduce memory usage\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)  # Smaller dense layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Build datasets\n",
    "    train_ds = build_dataset(\"/home/sala/data/general/train/\")\n",
    "    val_ds = build_dataset(\"/home/sala/data/general/test/\")\n",
    "    for img, label in train_ds.take(1):  \n",
    "     print(f\"Image shape: {img.shape}, Label: {label}\")\n",
    "\n",
    "    \n",
    "    # Build model\n",
    "    model = build_mobile_model()\n",
    "    \n",
    "    # Add early stopping to prevent overfitting/memory leaks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train with reduced batch size and memory monitoring\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import psutil  # For memory monitoring\n",
    "\n",
    "def generate_pseudo_labels(unlabeled_dir, model):\n",
    "    # Limit parallel workers to available CPU cores\n",
    "    num_workers = min(4, psutil.cpu_count())\n",
    "    \n",
    "    # Process in chunks to avoid memory spikes\n",
    "    image_paths = [os.path.join(unlabeled_dir, f) for f in os.listdir(unlabeled_dir)]\n",
    "    chunks = [image_paths[i:i+100] for i in range(0, len(image_paths), 100)]\n",
    "    \n",
    "    for chunk in tqdm(chunks, desc=\"Generating Pseudo-Labels\"):\n",
    "        with Pool(num_workers) as pool:\n",
    "            results = pool.map(preprocess_image, chunk)\n",
    "        \n",
    "        # Predict in batches\n",
    "        pseudo_labels = model.predict(\n",
    "            np.array(results),\n",
    "            batch_size=8  # Smaller batch for prediction\n",
    "        )\n",
    "        \n",
    "        # Save pseudo-labels to disk instead of keeping in memory\n",
    "        for path, label in zip(chunk, pseudo_labels):\n",
    "            np.save(f\"pseudo_labels/{os.path.basename(path)}.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dir):\n",
    "    test_ds = build_dataset(test_dir, batch_size=8)\n",
    "    \n",
    "    # Evaluate in batches to prevent OOM\n",
    "    results = []\n",
    "    for batch in tqdm(test_ds, desc=\"Evaluating Model\"):\n",
    "        preds = model.predict(batch, verbose=0)\n",
    "        results.extend(preds)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(np.argmax(results, axis=1) == ground_truth_labels)\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    model = train_model()\n",
    "    \n",
    "    # Generate pseudo-labels for unlabeled data\n",
    "    generate_pseudo_labels(\"/home/sala/data/soil_data/test/Black Soil\", model)\n",
    "    \n",
    "    # Evaluate the model\n",
    "#  evaluate_model(model, \"soil/test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
