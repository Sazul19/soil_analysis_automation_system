{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "synthetic_images_folder = \"/home/sala/data/synthetic_images\"\n",
    "real_images_folder = \"/home/sala/data/soil_images\"\n",
    "output_folder = \"/home/sala/data/organized_data\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(output_folder, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, \"val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, \"test\"), exist_ok=True)\n",
    "\n",
    "# Split synthetic images\n",
    "synthetic_images = [f for f in os.listdir(synthetic_images_folder) if f.endswith(('.jpg', '.png'))]\n",
    "train_synthetic, temp_synthetic = train_test_split(synthetic_images, test_size=0.2, random_state=42)\n",
    "val_synthetic, test_synthetic = train_test_split(temp_synthetic, test_size=0.5, random_state=42)\n",
    "\n",
    "# Move synthetic images to respective folders\n",
    "def move_images(image_list, source_folder, target_folder):\n",
    "    for img in image_list:\n",
    "        src_path = os.path.join(source_folder, img)\n",
    "        dst_path = os.path.join(target_folder, img)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "move_images(train_synthetic, synthetic_images_folder, os.path.join(output_folder, \"train\"))\n",
    "move_images(val_synthetic, synthetic_images_folder, os.path.join(output_folder, \"val\"))\n",
    "move_images(test_synthetic, synthetic_images_folder, os.path.join(output_folder, \"test\"))\n",
    "\n",
    "# Reserve real-world images for testing\n",
    "real_images = [f for f in os.listdir(real_images_folder) if f.endswith(('.jpg', '.png'))]\n",
    "move_images(real_images, real_images_folder, os.path.join(output_folder, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def resize_image(image_path, output_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Resize an image to a standard size.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): Path to the input image.\n",
    "        output_size (tuple): Target size (width, height).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Resized image.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, output_size)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lab(image):\n",
    "    \"\"\"\n",
    "    Convert an image from BGR to LAB color space.\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.ndarray): Input image in BGR format.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Image in LAB color space.\n",
    "    \"\"\"\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    return lab_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lighting(image):\n",
    "    \"\"\"\n",
    "    Normalize lighting using CLAHE (Contrast-Limited Adaptive Histogram Equalization).\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.ndarray): Input image in LAB color space.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Image with normalized lighting.\n",
    "    \"\"\"\n",
    "    # Split LAB channels\n",
    "    l, a, b = cv2.split(image)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_normalized = clahe.apply(l)\n",
    "    \n",
    "    # Merge channels back\n",
    "    normalized_lab = cv2.merge((l_normalized, a, b))\n",
    "    return normalized_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_image(image):\n",
    "    \"\"\"\n",
    "    Denoise an image using Gaussian blur.\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.ndarray): Input image in BGR or LAB format.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Denoised image.\n",
    "    \"\"\"\n",
    "    denoised_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    return denoised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, output_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocess an image by resizing, converting to LAB, normalizing lighting, and denoising.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): Path to the input image.\n",
    "        output_size (tuple): Target size (width, height).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed image in LAB color space.\n",
    "    \"\"\"\n",
    "    # Step 1: Resize image\n",
    "    resized_image = resize_image(image_path, output_size)\n",
    "    \n",
    "    # Step 2: Convert to LAB color space\n",
    "    lab_image = convert_to_lab(resized_image)\n",
    "    \n",
    "    # Step 3: Normalize lighting\n",
    "    normalized_lab = normalize_lighting(lab_image)\n",
    "    \n",
    "    # Step 4: Denoise (optional)\n",
    "    preprocessed_image = denoise_image(normalized_lab)\n",
    "    \n",
    "    return preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_in_folder(input_folder, output_folder, output_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocess all images in a folder and save them to an output folder.\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder (str): Path to the folder containing input images.\n",
    "        output_folder (str): Path to the folder to save preprocessed images.\n",
    "        output_size (tuple): Target size (width, height).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        input_path = os.path.join(input_folder, image_file)\n",
    "        output_path = os.path.join(output_folder, image_file)\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(input_path, output_size)\n",
    "        \n",
    "        # Save the preprocessed image\n",
    "        cv2.imwrite(output_path, preprocessed_image)\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"/home/sala/data/organized_data/val\"\n",
    "output_folder = \"/home/sala/data/organized_data/preprocessed_val\"\n",
    "preprocess_images_in_folder(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
