{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOTPrDECwy5oRWOsihayHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sazul19/soil_analysis_automation_system/blob/main/enhanced_model_prototype_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk61S8gTGpX6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load Pre-Trained EfficientNetB0 Model\n",
        "def build_model(num_classes):\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    # Add Custom Layers for Color Classification\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)  # Adjust num_classes for your color categories\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Prepare the Data\n",
        "def prepare_data(train_dir, val_dir, batch_size=32, img_size=(224, 224)):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rescale=1.0 / 255.0,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_generator = datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    val_generator = datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "    )\n",
        "\n",
        "    return train_generator, val_generator\n",
        "\n",
        "\n",
        "# Training Configuration\n",
        "def train_model(model, train_generator, val_generator, epochs=20, batch_size=32, learning_rate=0.001):\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint('efficientnet_color_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        validation_steps=val_generator.samples // batch_size,\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Define paths\n",
        "    train_dir = 'path/to/train/data'  # Replace with your train data path\n",
        "    val_dir = 'path/to/validation/data'  # Replace with your validation data path\n",
        "\n",
        "    # Prepare data\n",
        "    train_generator, val_generator = prepare_data(train_dir, val_dir)\n",
        "\n",
        "    # Build model\n",
        "    num_classes = len(train_generator.class_indices)  # Dynamically calculate number of color categories\n",
        "    model = build_model(num_classes)\n",
        "\n",
        "    # Train the model\n",
        "    history = train_model(model, train_generator, val_generator)\n",
        "\n",
        "    # Unfreeze the base model for fine-tuning\n",
        "    model.layers[0].trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Fine-tune the model\n",
        "    history_fine = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=10,\n",
        "        steps_per_epoch=train_generator.samples // 32,\n",
        "        validation_steps=val_generator.samples // 32,\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n"
      ]
    }
  ]
}